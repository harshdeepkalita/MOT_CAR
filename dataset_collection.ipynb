{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "840954c9-6bd0-4749-867c-d5e42039624f",
   "metadata": {},
   "source": [
    "Final Dataset =\n",
    "- COCO (vehicles only) : https://cocodataset.org/#download\n",
    "- UAVDT : https://sites.google.com/view/grli-uavdt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bfaa40-ba1b-44be-917a-9b4f074b7bc3",
   "metadata": {},
   "source": [
    "~/datasets/\n",
    " â””â”€â”€ coco2017/\n",
    "      â”œâ”€â”€ train2017/\n",
    "      â”œâ”€â”€ val2017/\n",
    "      â””â”€â”€ annotations/\n",
    "           â”œâ”€â”€ instances_train2017.json\n",
    "           â””â”€â”€ instances_val2017.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e98c9ff3-03e1-4269-b072-5afcf5520320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KAnnotations /Users/harshdeepkalita/projects/yolo26/datasets/coco2017/annotations/instances_train2017.json: 100% â”â”â”â”â”â”â”â”â”â”â”â” 117266/117266 8.4Kit/s 14.0s0.1s\n",
      "\u001b[KAnnotations /Users/harshdeepkalita/projects/yolo26/datasets/coco2017/annotations/instances_val2017.json: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4952/4952 9.8Kit/s 0.5s0.0s\n",
      "COCO data converted successfully.\n",
      "Results saved to /Users/harshdeepkalita/projects/yolo26/datasets/coco_vehicle_yolo\n"
     ]
    }
   ],
   "source": [
    "# pip install ultralytics\n",
    "#!pip install -U ultralytics\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.data.converter import convert_coco\n",
    "\n",
    "convert_coco(\n",
    "    labels_dir=\"datasets/coco2017/annotations\",\n",
    "    save_dir=\"datasets/coco_vehicle_yolo\",\n",
    ")\n",
    "\n",
    "# coco_vehicle_yolo/\n",
    "#  â”œâ”€â”€ images/\n",
    "#  â”‚    â”œâ”€â”€ train2017/\n",
    "#  â”‚    â””â”€â”€ val2017/\n",
    "#  â””â”€â”€ labels/\n",
    "#       â”œâ”€â”€ train2017/\n",
    "#       â””â”€â”€ val2017/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7df71292-351c-4dc7-ba2b-941a2e11fbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… COCO filtered to vehicle-only labels (no remapping).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "src_root = \"datasets/coco_vehicle_yolo\"\n",
    "dst_root = \"datasets/coco_vehicle_only\"\n",
    "\n",
    "vehicle_classes = [2, 5, 7]  # COCO YOLO IDs\n",
    "\n",
    "for split in [\"train2017\", \"val2017\"]:\n",
    "\n",
    "    src_img_dir = os.path.join(src_root, \"images\", split)\n",
    "    src_lbl_dir = os.path.join(src_root, \"labels\", split)\n",
    "\n",
    "    dst_img_dir = os.path.join(dst_root, \"images\", split)\n",
    "    dst_lbl_dir = os.path.join(dst_root, \"labels\", split)\n",
    "\n",
    "    os.makedirs(dst_img_dir, exist_ok=True)\n",
    "    os.makedirs(dst_lbl_dir, exist_ok=True)\n",
    "\n",
    "    for label_file in os.listdir(src_lbl_dir):\n",
    "\n",
    "        src_label_path = os.path.join(src_lbl_dir, label_file)\n",
    "\n",
    "        with open(src_label_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        filtered_lines = []\n",
    "\n",
    "        for line in lines:\n",
    "            cls_id = int(line.split()[0])\n",
    "            if cls_id in vehicle_classes:\n",
    "                filtered_lines.append(line)\n",
    "\n",
    "        if len(filtered_lines) > 0:\n",
    "            img_name = label_file.replace(\".txt\", \".jpg\")\n",
    "            src_img_path = os.path.join(src_img_dir, img_name)\n",
    "\n",
    "            if os.path.exists(src_img_path):\n",
    "                shutil.copy(src_img_path, os.path.join(dst_img_dir, img_name))\n",
    "\n",
    "                with open(os.path.join(dst_lbl_dir, label_file), \"w\") as f:\n",
    "                    f.writelines(filtered_lines)\n",
    "\n",
    "print(\"âœ… COCO filtered to vehicle-only labels (no remapping).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6099e4f4-867c-4d82-98ed-346c89ec1772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… UAVDT converted to YOLO format successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "uavdt_img_root = \"datasets/UAV-benchmark-M\"\n",
    "uavdt_gt_root = \"datasets/UAV-benchmark-MOTD_v1.0/GT\"\n",
    "output_root = \"datasets/vehicles\"\n",
    "\n",
    "train_img_dir = os.path.join(output_root, \"images/train\")\n",
    "val_img_dir = os.path.join(output_root, \"images/val\")\n",
    "train_lbl_dir = os.path.join(output_root, \"labels/train\")\n",
    "val_lbl_dir = os.path.join(output_root, \"labels/val\")\n",
    "\n",
    "os.makedirs(train_img_dir, exist_ok=True)\n",
    "os.makedirs(val_img_dir, exist_ok=True)\n",
    "os.makedirs(train_lbl_dir, exist_ok=True)\n",
    "os.makedirs(val_lbl_dir, exist_ok=True)\n",
    "\n",
    "train_ratio = 0.8\n",
    "\n",
    "all_sequences = sorted(os.listdir(uavdt_img_root))\n",
    "\n",
    "for seq in all_sequences:\n",
    "    seq_path = os.path.join(uavdt_img_root, seq)\n",
    "    gt_file = os.path.join(uavdt_gt_root, f\"{seq}_gt.txt\")\n",
    "\n",
    "    if not os.path.exists(gt_file):\n",
    "        continue\n",
    "\n",
    "    # Read annotations\n",
    "    annotations = {}\n",
    "    with open(gt_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\",\")\n",
    "\n",
    "            frame_id = int(parts[0])\n",
    "            x = float(parts[2])\n",
    "            y = float(parts[3])\n",
    "            w = float(parts[4])\n",
    "            h = float(parts[5])\n",
    "            category = int(parts[7])\n",
    "\n",
    "            # UAVDT categories:\n",
    "            # 1 = car\n",
    "            # 2 = truck\n",
    "            # 3 = bus\n",
    "            if category not in [1, 2, 3]:\n",
    "                continue\n",
    "\n",
    "            if frame_id not in annotations:\n",
    "                annotations[frame_id] = []\n",
    "\n",
    "            annotations[frame_id].append((x, y, w, h))\n",
    "\n",
    "    frame_ids = list(annotations.keys())\n",
    "    random.shuffle(frame_ids)\n",
    "\n",
    "    split_index = int(len(frame_ids) * train_ratio)\n",
    "    train_frames = set(frame_ids[:split_index])\n",
    "\n",
    "    for frame_id in frame_ids:\n",
    "        img_name = f\"img{frame_id:06d}.jpg\"\n",
    "        img_path = os.path.join(seq_path, img_name)\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        height, width = img.shape[:2]\n",
    "\n",
    "        yolo_lines = []\n",
    "        for (x, y, bw, bh) in annotations[frame_id]:\n",
    "            x_center = (x + bw / 2) / width\n",
    "            y_center = (y + bh / 2) / height\n",
    "            bw /= width\n",
    "            bh /= height\n",
    "\n",
    "            yolo_lines.append(f\"0 {x_center} {y_center} {bw} {bh}\")\n",
    "\n",
    "        new_name = f\"{seq}_{img_name}\"\n",
    "\n",
    "        if frame_id in train_frames:\n",
    "            img_dest = os.path.join(train_img_dir, new_name)\n",
    "            lbl_dest = os.path.join(train_lbl_dir, new_name.replace(\".jpg\", \".txt\"))\n",
    "        else:\n",
    "            img_dest = os.path.join(val_img_dir, new_name)\n",
    "            lbl_dest = os.path.join(val_lbl_dir, new_name.replace(\".jpg\", \".txt\"))\n",
    "\n",
    "        shutil.copy(img_path, img_dest)\n",
    "\n",
    "        with open(lbl_dest, \"w\") as f:\n",
    "            f.write(\"\\n\".join(yolo_lines))\n",
    "\n",
    "print(\"âœ… UAVDT converted to YOLO format successfully.\")\n",
    "# /Users/harshdeepkalita/datasets/vehicle/\n",
    "#  â”œâ”€â”€ images/\n",
    "#  â”‚    â”œâ”€â”€ train/\n",
    "#  â”‚    â””â”€â”€ val/\n",
    "#  â”œâ”€â”€ labels/\n",
    "#  â”‚    â”œâ”€â”€ train/\n",
    "#  â”‚    â””â”€â”€ val/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bb0ee13-5463-4988-a620-685b395cdfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Merged 16270 images into train\n",
      "âœ… Merged 707 images into val\n",
      "ðŸŽ¯ COCO successfully merged into vehicles dataset.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "uav_root = \"datasets/vehicles\"\n",
    "coco_root = \"datasets/coco_vehicle_only\"\n",
    "\n",
    "def merge_split(split_src, split_dst):\n",
    "\n",
    "    src_img_dir = os.path.join(coco_root, \"images\", split_src)\n",
    "    src_lbl_dir = os.path.join(coco_root, \"labels\", split_src)\n",
    "\n",
    "    dst_img_dir = os.path.join(uav_root, \"images\", split_dst)\n",
    "    dst_lbl_dir = os.path.join(uav_root, \"labels\", split_dst)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for label_file in os.listdir(src_lbl_dir):\n",
    "\n",
    "        src_label_path = os.path.join(src_lbl_dir, label_file)\n",
    "        img_name = label_file.replace(\".txt\", \".jpg\")\n",
    "        src_img_path = os.path.join(src_img_dir, img_name)\n",
    "\n",
    "        if not os.path.exists(src_img_path):\n",
    "            continue\n",
    "\n",
    "        # Add prefix to avoid collision\n",
    "        new_img_name = \"coco_\" + img_name\n",
    "        new_lbl_name = \"coco_\" + label_file\n",
    "\n",
    "        shutil.copy(src_img_path, os.path.join(dst_img_dir, new_img_name))\n",
    "        shutil.copy(src_label_path, os.path.join(dst_lbl_dir, new_lbl_name))\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    print(f\"âœ… Merged {count} images into {split_dst}\")\n",
    "\n",
    "# Merge train\n",
    "merge_split(\"train2017\", \"train\")\n",
    "\n",
    "# Merge val\n",
    "merge_split(\"val2017\", \"val\")\n",
    "\n",
    "print(\"ðŸŽ¯ COCO successfully merged into vehicles dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e82117b-684d-4a5c-8cb0-c929db275f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS available: True\n",
      "MPS built: True\n",
      "Ultralytics 8.4.14 ðŸš€ Python-3.8.19 torch-2.3.1 MPS (Apple M3 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=6, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=datasets/vehicles/vehicle.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=832, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo26s.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=MuSGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=True, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/Users/harshdeepkalita/projects/yolo26/runs/detect/train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=True, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding class names with single class.\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "print(\"MPS built:\", torch.backends.mps.is_built())\n",
    "\n",
    "model = YOLO(\"yolo26s.pt\")\n",
    "\n",
    "model.train(\n",
    "    data=\"datasets/vehicles/vehicle.yaml\",\n",
    "    imgsz=832,\n",
    "    epochs=100,\n",
    "    batch=6,\n",
    "    device=\"mps\",\n",
    "    rect=True,\n",
    "    optimizer=\"MuSGD\",\n",
    "    cos_lr=True,\n",
    "    patience=20,\n",
    "    single_cls=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b8e6d1-7d2c-4f1b-a06b-ddcdb3a8cff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
